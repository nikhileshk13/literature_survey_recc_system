{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = rf'N:\\arxiv_dataset\\arxiv-metadata-oai-snapshot.json'\n",
    "chunk_size = 100000\n",
    "data = pd.read_json(json_file, lines=True, chunksize=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "chunks = []\n",
    "for chunk in data:\n",
    "    # drop the columns that are not needed\n",
    "    chunk.drop(['id', 'authors', 'comments', 'journal-ref', 'report-no', 'categories', 'license', 'versions', 'authors_parsed'], axis=1, inplace=True)\n",
    "    chunks.append(chunk)\n",
    "    ctr+=1\n",
    "    if ctr>2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           100000 non-null  float64\n",
      " 1   submitter    100000 non-null  object \n",
      " 2   title        100000 non-null  object \n",
      " 3   doi          61372 non-null   object \n",
      " 4   abstract     100000 non-null  object \n",
      " 5   update_date  100000 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "chunks[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 100000 to 199999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           100000 non-null  float64\n",
      " 1   submitter    100000 non-null  object \n",
      " 2   title        100000 non-null  object \n",
      " 3   doi          60048 non-null   object \n",
      " 4   abstract     100000 non-null  object \n",
      " 5   update_date  100000 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "chunks[1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the null values in doi\n",
    "chunks[0] = chunks[0].dropna()\n",
    "chunks[1] = chunks[1].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 61372 entries, 0 to 99998\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           61372 non-null  float64\n",
      " 1   submitter    61372 non-null  object \n",
      " 2   title        61372 non-null  object \n",
      " 3   doi          61372 non-null  object \n",
      " 4   abstract     61372 non-null  object \n",
      " 5   update_date  61372 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "chunks[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 60048 entries, 100000 to 199997\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           60048 non-null  float64\n",
      " 1   submitter    60048 non-null  object \n",
      " 2   title        60048 non-null  object \n",
      " 3   doi          60048 non-null  object \n",
      " 4   abstract     60048 non-null  object \n",
      " 5   update_date  60048 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "chunks[1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([chunks[0], chunks[1]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 121420 entries, 0 to 199997\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           121420 non-null  float64\n",
      " 1   submitter    121420 non-null  object \n",
      " 2   title        121420 non-null  object \n",
      " 3   doi          121420 non-null  object \n",
      " 4   abstract     121420 non-null  object \n",
      " 5   update_date  121420 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>update_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>2008-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>704.0006</td>\n",
       "      <td>Yue Hin Pong</td>\n",
       "      <td>Bosonic characters of atomic Cooper pairs acro...</td>\n",
       "      <td>10.1103/PhysRevA.75.043613</td>\n",
       "      <td>We study the two-particle wave function of p...</td>\n",
       "      <td>2015-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>704.0007</td>\n",
       "      <td>Alejandro Corichi</td>\n",
       "      <td>Polymer Quantum Mechanics and its Continuum Limit</td>\n",
       "      <td>10.1103/PhysRevD.76.044016</td>\n",
       "      <td>A rather non-standard quantum representation...</td>\n",
       "      <td>2008-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>704.0008</td>\n",
       "      <td>Damian Swift</td>\n",
       "      <td>Numerical solution of shock and ramp compressi...</td>\n",
       "      <td>10.1063/1.2975338</td>\n",
       "      <td>A general formulation was developed to repre...</td>\n",
       "      <td>2009-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>704.0009</td>\n",
       "      <td>Paul Harvey</td>\n",
       "      <td>The Spitzer c2d Survey of Large, Nearby, Inste...</td>\n",
       "      <td>10.1086/518646</td>\n",
       "      <td>We discuss the results from the combined IRA...</td>\n",
       "      <td>2010-03-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          submitter  \\\n",
       "0  704.0001     Pavel Nadolsky   \n",
       "5  704.0006       Yue Hin Pong   \n",
       "6  704.0007  Alejandro Corichi   \n",
       "7  704.0008       Damian Swift   \n",
       "8  704.0009        Paul Harvey   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "5  Bosonic characters of atomic Cooper pairs acro...   \n",
       "6  Polymer Quantum Mechanics and its Continuum Limit   \n",
       "7  Numerical solution of shock and ramp compressi...   \n",
       "8  The Spitzer c2d Survey of Large, Nearby, Inste...   \n",
       "\n",
       "                          doi  \\\n",
       "0  10.1103/PhysRevD.76.013009   \n",
       "5  10.1103/PhysRevA.75.043613   \n",
       "6  10.1103/PhysRevD.76.044016   \n",
       "7           10.1063/1.2975338   \n",
       "8              10.1086/518646   \n",
       "\n",
       "                                            abstract update_date  \n",
       "0    A fully differential calculation in perturba...  2008-11-26  \n",
       "5    We study the two-particle wave function of p...  2015-05-13  \n",
       "6    A rather non-standard quantum representation...  2008-11-26  \n",
       "7    A general formulation was developed to repre...  2009-02-05  \n",
       "8    We discuss the results from the combined IRA...  2010-03-18  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to clean the abstract\n",
    "def clean_abstract(abstract):\n",
    "    try:\n",
    "\n",
    "        abstract = re.sub(r'\\\\href{[^}]+}{[^}]+}', '', abstract) # remove the \\href tags in the abstract\n",
    "        abstract = re.sub(r'\\\\frac\\s*{[^}]+}\\s*{[^}]+}', '', abstract) # remove the \\frac tags in the abstract\n",
    "        abstract = abstract.replace('\\n', ' ') # removing the newline escape character\n",
    "\n",
    "        # dealing the other latex tags in the abstract and converting them to readable form\n",
    "        latex_converter = LatexNodes2Text()\n",
    "        readable_abstract = latex_converter.latex_to_text(abstract)\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error processing text: {e}\")\n",
    "        readable_abstract = None\n",
    "\n",
    "    return readable_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fucntion to clean the submitter names\n",
    "def clean_submitter(submitter):\n",
    "    try:\n",
    "\n",
    "        # cleaning the escape characters in the submitter name\n",
    "        submitter = submitter.replace(\"\\\\'\", '').replace('\\\\\"', '')\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        submitter = None\n",
    "\n",
    "    return submitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fucntion to clean the titles\n",
    "def clean_title(title):\n",
    "    try:\n",
    "\n",
    "        cleaned_title = title.replace('\\n', ' ') # cleaning the newline escape character\n",
    "\n",
    "        # dealing the latex tags in the title and converting them to readable form\n",
    "        latex_converter = LatexNodes2Text()\n",
    "        readable_title = latex_converter.latex_to_text(cleaned_title)\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        readable_title = None\n",
    "\n",
    "    return readable_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the abstract, submitter and title columns and insert an id column\n",
    "data['abstract'] = data['abstract'].apply(clean_abstract)\n",
    "data['submitter'] = data['submitter'].apply(clean_submitter)\n",
    "data['title'] = data['title'].apply(clean_title)\n",
    "data.insert(0, 'id', range(0, data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 121420 entries, 0 to 199997\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           121420 non-null  int64 \n",
      " 1   submitter    121420 non-null  object\n",
      " 2   title        121420 non-null  object\n",
      " 3   doi          121420 non-null  object\n",
      " 4   abstract     121420 non-null  object\n",
      " 5   update_date  121420 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(rf'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "num_chunks = len(data) // chunk_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data in small chunks of 1000\n",
    "for i, chunk in enumerate(np.array_split(data, num_chunks)):\n",
    "    chunk.to_csv(rf\"N:\\arxiv_dataset\\github_121420\\chunks_1000\\data\\{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature_survey_recc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
